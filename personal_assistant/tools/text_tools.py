from __future__ import annotations

import json
import re
from pathlib import Path

from .base_tool import BaseTool


_FILES_DIR = Path(__file__).resolve().parents[2] / "files"
_FILES_DIR.mkdir(parents=True, exist_ok=True)
_PROCUREMENT_RESULTS_PATH = _FILES_DIR / "motorcycle_procurement.json"


class TextTools(BaseTool):
    def generate_ideas(self, topic: str) -> str:
        """Ask Gemini to brainstorm blog post idea for a topic."""
        resp = self.model.generate_content(
            f"Brainstorm 4â€“6 creative blog post ideas for the topic:\n\n{topic}"
        )
        return resp.text

    def write_content(self, ideas: str) -> str:
        """Ask Gemini to expand an outline into a ~300-word draft."""
        resp = self.model.generate_content(
            "Expand the following outline into a cohesive ~300-word blog post:\n\n"
            f"{ideas}"
        )
        return resp.text

    def format_draft(self, draft: str) -> str:
        """Ask Gemini to format the draft as clean Markdown."""
        resp = self.model.generate_content(
            "Format this draft as clean Markdown with headings, sub-headings, and bullet lists:\n\n"
            f"{draft}"
        )
        return resp.text

    def perform_task(self, task_prompt: str, context: str | None = None) -> str:
        """
        Ask Gemini to perform an arbitrary knowledge-work task with optional context.

        A small helper for dynamically created agents that all share the same tool.
        """
        prompt_parts: list[str] = []
        if context:
            prompt_parts.append(
                "You may rely on the following context generated by previous agents:\n"
                f"{context.strip()}\n\n"
            )
        prompt_parts.append(
            "Carry out the task below carefully. Return only the finished deliverable.\n\n"
            f"{task_prompt.strip()}"
        )
        resp = self.model.generate_content("".join(prompt_parts))
        return resp.text

    def finalize_motorcycle_results(self, listings_json: str) -> str:
        """
        Validate and polish the procurement JSON for 2-stroke motorcycle searches.
        """
        prompt = (
            "You are the quality auditor for motorcycle procurement data. "
            "Review the draft JSON below, ensure it follows the required schema, "
            "contains only dirt/enduro 2-stroke listings, obeys the hard filters "
            "(200-300 cc, <= 10,000 AUD, 500 km of Brisbane, year >= 2006). "
            "Confirm that rankings (Top 5, priority_rank) reflect distance first, "
            "then price, then completeness. "
            "Normalise fields (stroke must be '2-stroke', numeric values must be numbers, "
            "null where unavailable). Return ONLY the corrected JSON object with the same "
            "structure: scraped_at, listings[...], top_5_ids. Do not add commentary.\n\n"
            f"{listings_json.strip()}"
        )
        resp = self.model.generate_content(prompt)
        raw_text = resp.text or ""
        candidate = self._normalise_procurement_payload(raw_text).strip()
        if not candidate and raw_text:
            candidate = raw_text.strip()
        try:
            parsed = json.loads(candidate)
        except json.JSONDecodeError:
            parsed = None
        self._persist_procurement_results(candidate, raw_text)
        if parsed is not None:
            return json.dumps(parsed, indent=2)
        return candidate

    def design_agent_plan(self, goal: str) -> str:
        """
        Ask Gemini to propose a workflow of agents given a user goal.

        The response MUST be valid JSON with keys: workflow_name (snake_case),
        workflow_description, and agents (list of objects containing name,
        description, task_prompt, optional instruction, optional output_key).
        """
        resp = self.model.generate_content(
            "You are an AI engineer who designs small teams of agents that collaborate.\n"
            "Given the goal below, produce a detailed plan in JSON format with the keys:\n"
            "workflow_name (snake_case identifier), workflow_description, and agents.\n"
            "Each agent object should include: name (CapWords), description, task_prompt "
            "that will be supplied to a generic `perform_task` tool, optional instruction "
            "overrides, and optional output_key (snake_case). Do not include any "
            "additional prose outside of the JSON payload.\n\n"
            f"Goal:\n{goal.strip()}"
        )
        return resp.text

    @staticmethod
    def _persist_procurement_results(payload: str, raw_payload: str = "") -> None:
        """
        Overwrite the saved procurement report with the latest payload.

        The saved file always reflects the most recent search results. When the payload is not valid
        JSON, the raw text is still written so callers can inspect the model output.
        """
        candidate = payload or raw_payload
        if not candidate:
            return
        try:
            parsed = json.loads(candidate)
        except json.JSONDecodeError:
            _PROCUREMENT_RESULTS_PATH.write_text(candidate, encoding="utf-8")
            return
        with _PROCUREMENT_RESULTS_PATH.open("w", encoding="utf-8") as handle:
            json.dump(parsed, handle, indent=2)
            handle.write("\n")

    @staticmethod
    def _normalise_procurement_payload(payload: str) -> str:
        """
        Remove Markdown code fences and leading JSON annotations from LLM responses.
        """
        if not payload:
            return ""
        text = payload.strip()
        fence_match = re.search(r"```(?:json)?\s*(.*?)\s*```", text, re.IGNORECASE | re.DOTALL)
        if fence_match:
            return fence_match.group(1).strip()
        return text
